#summary Discussion about how the service will horizontally scale to deal with storage problems and real-time indexing speed.

= Introduction =

The indexserver as it stands today is really two parts: a parser and an indexer. Profiling shows that parsing takes most of the time when we're receiving a message. Since we're using message bus technology, scaling horizontally is easy (message-wise).

= Details =

The indexserver will split into two components: parseserver and indexserver. All of the LogStash agents will write the raw log lines to a shared message queue. The parseservers will all subscribe to the same queue (which will end up in a round-robin distribution of raw log lines to the various parseservers). The parseservers do the heavy lifting (grok, strptime, etc) and send the parsed results up to the indexserver queue.

To scale indexing time (and more storage, really), we support running multiple indexservers. They cannot point at the same source (NAS/SAN/same disk/whatever) because ferret requires an exclusive write lock. This means that we also need to run a searchserver on each indexserver machine to make the disparate indexes available.

Parseservers and indexservers can live on the same machine. Since they are not multi-threaded (ruby threading has a global interpreter lock), if you have an N-core machine, it's reasonable to run N total parseservers/indexservers on that machine (beware of I/O, though).

Traditionally, ferret itself does the "merging" of results. Instead, we're going to include a sample class that can send out a search to all the searchservers (via a message bus topic? have to figure out when we're "done" searching). The program doing the searching will receive all of the various results, and do the merging server-side.

This prevents us from doing "score-based" sorting (a feature of ferret). We think this is probably an OK thing; we figure the most useful usage of a product like this is range based with a filter (i.e. show me all apache GET requests between Monday and Wednesday). The searching agent can easily merge the results and sort by @DATE (or even another key). There are still scores associated with each document, but they are only relevant to the documents on the same indexserver -- so it would be a mistake (search quality wise) to merge all of the results together and sort by score.

= Data =

I (jordan) did some to look at places where we're doing too much and could do with some simple optimizations. After doing some optimizing, here are my results:

Configuration:

System: 
  * 1 host, 4 x 2gHz
Code: 
  * cgrok + grok ruby at svn 2249
  * logstash at svn 109

Configuration:
  * stompserver, run without arguments.
  * logparsed running 4 processes
  * 1 agent feeding 8000 lines of haproxy logs
  * 2 logstashd indexers
  * Everything talking to 'localhost'

Final output from the parsers:
  * rate: 245.16/sec
  * rate: 265.00/sec
  * rate: 268.21/sec
  * rate: 272.75/sec

Final output from the indexers:
  * rate: 345.26/sec
  * rate: 423.09/sec

Timing a single indexer on those same 8000 inputs took 24 seconds: 9.12s user 3.60s system 53% cpu 23.928 total