#summary The roadmap of Doom!
#labels roadmap

= Roadmap for 1.0 =

Overall priorities for 1.0: quality and stability before features

  * If it's a feature, it's likely to be deferred.
  * If it's a destabilizing change, I want it to happen before 1.0.
  * If it's a piece of code, I want tests for it before 1.0.

Ruby Support:

  * Ruby 1.8.7 - will support with all tests passing.
  * Ruby 1.8.6 - will try to support with most/all tests passing.
  * Ruby 1.9.x - will not support

We cannot yet support ruby 1.9.2 as the ruby standard library differences (both
documented and undcumented) between 1.8.7 and 1.9.x (and even between 1.9.x
releases) are too wild to support reasonably in the logstash 1.0 time frame.
Further, very few things ship ruby 1.9 making for another difficult-to-acquire
dependency.

Feature goals

  * _DONE_ Fully-supported pipe metaphor: inputs, filters, outputs.
  * Inputs: 
    * _DONE_ file
    * exec
    * _DONE_ amqp
    * _DONE_ stomp
    * _DONE_ syslog
    * _DONE_ tcp
  * Input variations: file+json, etc. (will be filters)
  * Filters
    * _DONE_ grok
    * _DONE_ multiline
    * _DONE_ something grep-like
    * key value parse
    * something sed-like
    * json
  * Outputs
    * _DONE_ amqp
    * _DONE_ beanstalk
    * _DONE_ elasticsearch
    * _DONE_ graylog2
    * _DONE_ mongodb
    * _DONE_ nagios
    * _DONE_ stdout
    * _DONE_ stomp
    * _DONE_ tcp (needs specification)
    * _DONE_ websockets
    * syslog
  * A default search web interface - elasticsearch only (for 1.0)
  * Basic real-time search web interface through websockets.
  * Be stable with 10k events/sec going through the system of file input -> amqp -> elasticsearch on reasonably-modern hardware. See [KnownPerformanceIssues]

Supported/documented configurations:
  * standalone: local files through to elasticsearch
  * piped: local files to amqp, amqp to a filter to amqp, amqp to elasticsearch
  * document ways to send input (logstash agent, syslog-ng, rsyslog, flume) 

Code quality
  * Logstash agents should be debuggable through logging.
  * Each component (input/output/filter) must have tests.
  * Agent must have tests.

Documentation goals
  * ElasticSearch indexes, etc, should be automatically configured by logstash.
  * Configuration: tags, inputs, outputs, filters, etc.
  * Document how to configure elasticsearch. Indexing, sharding, mapping, etc.
  * Document best practices
  * Consistent terminology ("input", "output", "event", "filter", etc).

Other todos:

  * beanstalk input+output
  * stomp input+output
  * nagios output (to a passive service)  
  * nagios input (global or otherwise, event handler -> logstash)
  * search analytics prototype (search -> filters -> {results, graph})
  * Plan for handling input/filter/output as plugins
  * Make 'logstash' gem thin ?
  * Make 'logstash-all' gem heavy ?
  * Make 'logstash-{input,filter,output}-somename' gems
  * Work on CentOS5 support (host ruby 1.8.7 and other packages somewhere)
  * DONE - Daemonizing for logstash and logstash-web

= > 1.0 (or otherwise untargeted) =

(This list is unprioritized)

  * DONE Multi-line event support (will be a filter)
  * DONE More grok patterns (java stacktrace, etc)
  * "nearby" log event query (i.e. find events near a stacktrace)
  * Saved queries
  * Customizable reports
  * Schedulable queries
  * Users, accounting, search data protection (hide certain results from some users, etc)
  * Better visuals: More than just histograms on search hits.
  * hit graph with selectable group-by stacking
  * Suggested field values in a query
  * document how to log directly to logstash
  * web api
  * web api aggregates query?

= Interactive Analytics =

Interactive querying/analytics flow: search, interactively build a
grok filter based on results, add any other filters (multiline,
etc), choose output (what kind of graph, what results you want to
see, what aggregation, etc).

Save-able analytics for later reports, alerting, etc.

Graphs? Histogram, pie (mmmm, pie.), directed graphs (for tracking RPC and
session calls), etc.

== "VS" graphs ==

Compare two queries. Use case: comparing monitoring alerts with other logs.

== "BY" graphs ==

Aggregate by field(s). Use case: contrasting HTTP response codes

= Web UI =

Parts: search, analytics, stream, others?

  * Search: main search interface
  * Analytics: interactive search/drill/filter/aggregate/graph.
  * Stream: watch logs in real time through filters.

= Interop =

  * Use the agent, or don't.
  * Use the web ui, or don't.
  * Use a component, or dont.

Modularity and interoperability is critical. Logstash isn't a silo. I want you
to be able to use logstash in whatever way most compliments your
infrastructure.

  * Using flume to ship logs to logstash
  * Using flume to ship into hdfs and elasticsearch, use logstash's web ui on top of elasticsearch
  * Using rsyslog and syslog-ng to ship to logstash
  * Using the logstash agent to ship to graylog2
  * Using the logstash pipe model (input/filter/output) for other tools (hadoop, etc)
