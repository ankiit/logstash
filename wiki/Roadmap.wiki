#summary The roadmap of Doom!
#labels roadmap

= Roadmap for 1.0 =

Feature goals
  * _DONE_ Fully-supported pipe metaphor: inputs, filters, outputs.
  * Inputs: 
    * _DONE_ file
    * exec
    * _DONE_ amqp
    * stomp
    * _DONE_ syslog
    * _DONE_ tcp
  * Input variations: file+json, etc. (will be filters)
  * Filters
    * _DONE_ grok
    * _DONE_ multiline
    * something grep-like
    * key value parse
    * something sed-like
    * json
    * 
  * Outputs
    * _DONE_ stdout
    * _DONE_ amqp
    * stomp
    * tcp
    * syslog
    * _DONE_ mongodb
    * _DONE_ elasticsearch
    * _DONE_ websockets
  * A default search web interface - elasticsearch only (for 1.0)
  * Basic real-time search web interface through websockets.
  * Be stable with 10k events/sec going through the system of file input -> amqp -> elasticsearch on reasonably-modern hardware. See [KnownPerformanceIssues]

Supported/documented configurations:
  * standalone: local files through to elasticsearch
  * piped: local files to amqp, amqp to a filter to amqp, amqp to elasticsearch
  * document ways to send input (logstash agent, syslog-ng, rsyslog, flume) 

Code quality
  * Logstash agents should be debuggable through logging.
  * Each component (input/output/filter) must have tests.
  * Agent must have tests.

Documentation goals
  * ElasticSearch indexes, etc, should be automatically configured by logstash.
  * Configuration: tags, inputs, outputs, filters, etc.
  * Document how to configure elasticsearch. Indexing, sharding, mapping, etc.
  * Document best practices
  * Consistent terminology ("input", "output", "event", "filter", etc).

= Christmas Hackfest =

  * Mega testing work - all inputs, filters, and outputs need testing.
  * Web interface testing

Other todos:

  * beanstalk input+output
  * stomp input+output
  * nagios output (to a passive service)  
  * nagios input (global or otherwise, event handler -> logstash)
  * search analytics prototype (search -> filters -> {results, graph})
  * Plan for handling input/filter/output as plugins
  * Make 'logstash' gem thin ?
  * Make 'logstash-all' gem heavy ?
  * Make 'logstash-{input,filter,output}-somename' gems
  * Work on CentOS5 support (host ruby 1.8.7 and other packages somewhere)
  * DONE - Daemonizing for logstash and logstash-web

= > 1.0 (or otherwise untargeted) =

(This list is unprioritized)

  * DONE Multi-line event support (will be a filter)
  * DONE More grok patterns (java stacktrace, etc)
  * "nearby" log event query (i.e. find events near a stacktrace)
  * Saved queries
  * Customizable reports
  * Schedulable queries
  * Users, accounting, search data protection (hide certain results from some users, etc)
  * Better visuals: More than just histograms on search hits.
  * hit graph with selectable group-by stacking
  * Suggested field values in a query
  * document how to log directly to logstash
  * web api
  * web api aggregates query?

= Interactive Analytics =

Interactive querying/analytics flow: search, interactively build a
grok filter based on results, add any other filters (multiline,
etc), choose output (what kind of graph, what results you want to
see, what aggregation, etc).

Save-able analytics for later reports, alerting, etc.

Graphs? Histogram, pie (mmmm, pie.), directed graphs (for tracking RPC and
session calls), etc.

== "VS" graphs ==

Compare two queries. Use case: comparing monitoring alerts with other logs.

== "BY" graphs ==

Aggregate by field(s). Use case: contrasting HTTP response codes

= Web UI =

Parts: search, analytics, stream, others?

  * Search: main search interface
  * Analytics: interactive search/drill/filter/aggregate/graph.
  * Stream: watch logs in real time through filters.

= Interop =

  * Use the agent, or don't.
  * Use the web ui, or don't.
  * Use a component, or dont.

Modularity and interoperability is critical. Logstash isn't a silo. I want you
to be able to use logstash in whatever way most compliments your
infrastructure.

  * Using flume to ship logs to logstash
  * Using flume to ship into hdfs and elasticsearch, use logstash's web ui on top of elasticsearch
  * Using rsyslog and syslog-ng to ship to logstash
  * Using the logstash agent to ship to graylog2
  * Using the logstash pipe model (input/filter/output) for other tools (hadoop, etc)